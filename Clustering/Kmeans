//算法名称-K-means
import org.apache.spark.sql.{DataFrame, Row, SQLContext}
import org.apache.spark.{SparkContext, SparkConf}
import cn.neucloud.dasuan.SparkContextImpl
import cn.neucloud.dasuan.analysis.clustering.KMeans
import org.apache.spark.ml.linalg.Vectors

val dataset: DataFrame = spark.sqlContext.createDataFrame(Seq(
      (1, Vectors.dense(0.0, 0.0, 0.0)),
      (2, Vectors.dense(0.1, 0.1, 0.1)),
      (3, Vectors.dense(0.2, 0.2, 0.2)),
      (4, Vectors.dense(9.0, 9.0, 9.0)),
      (5, Vectors.dense(9.1, 9.1, 9.1)),
      (6, Vectors.dense(9.2, 9.2, 9.2))
    )).toDF("id", "features")

// Trains a k-means model.
val kmeans = new KMeans("11").setK(2).setSeed(1L)
val model = kmeans.fit(dataset)

// Evaluate clustering by computing Within Set Sum of Squared Errors.
val WSSSE = model.computeCost(dataset)
println(s"Within Set Sum of Squared Errors = $WSSSE")

// Shows the result.
println("Cluster Centers: ")
model.clusterCenters.foreach(println)

val kmsummary = model.summary.clusterSizes
val sili = model.summary.silin
val ouj = model.summary.ouj

println("Contour factor: " + sili)
println("Euclidean distance:" + ouj)
println("predict (9.21, 9.21, 9.21) = " + model.predict(Vectors.dense(9.21, 9.21, 9.21)))
println("-----------------")
